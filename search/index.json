[{"content":" 本节课件链接1 本节课件链接2 本节课件链接3\n面向对象的程序设计 面向对象的程序设计方法:\n将某类客观事物共同特点 (属性) 归纳出来, 形成一个数据结构 (可以用多个变量描述事物的属性); 将这类事物所能进行的行为也归纳出来, 形成一个个函数, 这些函数可以用来操作数据结构. 面向对象的特点有 抽象, 封装, 继承, 多态.\n一般来说, 对象所占用的内存空间的大小, 等于所有成员变量的大小之和.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class CRectangle { public: int w, h; int Area() { return w * h; } int Perimeter() { return 2 * (w + h); } void Init(int w_, int h_) { w = w_; h = h_; } }; // 必须有分号 int main() { int w, h; CRectangle r; // r 是一个对象 cin \u0026gt;\u0026gt; w \u0026gt;\u0026gt; h; r.Init(w, h); cout \u0026lt;\u0026lt; r.Area() \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; r.Perimeter(); return 0; } 和结构变量一样, 对象之间可以用 = 进行赋值, 但是不能用 ==, !=, \u0026gt;, \u0026lt;, \u0026gt;=, \u0026lt;= 进行比较, 除非这些运算符经过了 重载.\n对象名.成员名 1 2 3 CRectangle r1, r2; r1.w = 5; r2.Init(5, 4); 指针-\u0026gt;成员名 1 2 3 4 5 CRectangle r1, r2; CRectangle *p1 = \u0026amp;r1; CRectangle *p2 = \u0026amp;r2; p1-\u0026gt;w = 5; p2-\u0026gt;Init(5, 4); 引用名.成员名 1 2 3 CRectangle r1; CRectangle \u0026amp;rr = r1; rr.w = 5; 引用 引用名是对象名的别名, 指向同一个对象. 语法: 类名 \u0026amp;引用名 = 对象名; 引用的好处是可以减少指针的使用, 使得代码更加简洁.\n1 2 3 4 5 6 7 8 9 // 要用指针, 否则参数传递会产生拷贝 void swap(int *a, int *b) { int tmp; tmp = *a; *a = *b; *b = tmp; } int n1, n2; swap(\u0026amp;n1, \u0026amp;n2); 可以改写为:\n1 2 3 4 5 6 7 8 void swap(int \u0026amp;a, int \u0026amp;b) { int tmp; tmp = a; a = b; b = tmp; } int n1, n2; swap(n1, n2); 引用还可以作为函数的返回值.\n1 2 3 4 5 6 int \u0026amp;ref(int \u0026amp;a) { return a; } int n = 5; ref(n) = 6; // n = 6 常量, 常引用, 常量指针 定义引用时, 前面加 const 关键字, 表示 常引用. 不能通过常引用修改对象的值, 即只读引用.\n1 2 3 4 int n; const int \u0026amp;r = n; r = 5; // 错误 n = 5; // 正确 const T\u0026amp; 和 T\u0026amp; 是不同的类型. T\u0026amp; 类型的引用或 T 类型的变量可以用来初始化 const T\u0026amp; 类型的引用. const T 类型的常变量和 const T\u0026amp; 类型的引用则不能用来初始化 T\u0026amp; 类型的引用, 除非进行强制类型转换. 不可通过常量指针修改其指向的内容, 但可以修改指针的指向 (引用不可以).\n1 2 3 4 5 int n, m; const int *p = \u0026amp;n; *p = 5; // 错误 n = 5; // 正确 p = \u0026amp;m; // 正确 函数参数为常量指针时, 可避免函数内部不小心改变参数指针所指地方的内.\n1 2 3 4 void myPrintf(const int *p) { *p = 5; // 错误 p = \u0026amp;m; // 正确 } 类成员的访问控制 public: 公有成员, 可以在类的外部访问. private: 私有成员, 只能在类的内部访问, 缺省默认为 private. protected: 保护成员, 只能在类的内部和派生类中访问. 1 2 3 4 5 6 7 8 9 class className { // 这三个关键字可以出现多次, 没有顺序要求 private: //私有属性和函数 public: //公有属性和函数 protected: //保护属性和函数 }; 类内部可以访问当前对象和同类其他对象的私有成员.\n\u0026ldquo;隐藏\u0026rdquo; 的目的是强制对成员变量的访问一定要通过成员函数进行, 那么以后成员变量的类 型等属性修改后, 只需要更改成员函数即可.\nstruct 和 class 的唯一区别是默认的访问控制权限不同, struct 默认为 public, class 默认为 private.\n函数重载和缺省参数 函数名相同, 参数个数或类型不同, 注意没有返回值类型不同.\n1 2 3 double _max(double f1, double f2); int _max(int n1, int n2); int _max(int n1, int n2, int n3); C++ 中, 定义函数的时候可以让 最右边 的连续若干个参数有缺省值, 那么调用函数的时候, 若相应位置不写参数, 参数就是缺省值.\n1 2 3 4 void func(int a, int b = 0, int c = 0); func(1); // a = 1, b = 0, c = 0 func(1, 2); // a = 1, b = 2, c = 0 func(1, , 8); // 错误 成员函数也可以重载或有缺省参数.\n构造函数 构造函数是一种特殊的成员函数: 名字与类名相同, 没有返回值 (void 也不行). 作用是初始化对象的数据成员.\n如果定义类时没有定义构造函数, 编译器会生成一个默认的无参构造函数. 如果定义了, 默认构造函数就不会生成. 对象生成时, 构造函数自动调用. 生成之后不能再执行构造函数. 一个类可以有多个构造函数, 可以重载.\n1 2 3 4 5 6 7 8 9 10 11 class Complex { private: double real; double imag; public: void Set(double r, double i); }; //编译器自动生成默认构造函数 // 两种写法均可. Complex c1; Complex *pc = new Complex; 手动加入构造函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Complex { private: double real; double imag; public: Complex(double r, double i = 0) { // 带缺省参数 real = r; imag = i; } }; Complex *pc1 = new Complex; // error, 没有参数 Complex c2(2); // OK Complex *pc2 = new Complex(3, 4); 构造当然也可以 private, 这样就不能用来生成对象, 但是可以用来实现单例模式.\n构造函数还可以用在数组.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class CSample { int x; public: CSample() {} CSample(int n) { x = n; } CSample(int m, int n) { x = m + n; } }; int main() { CSample array1[2]; // 两次无参 CSample array2[2] = {4, CSample(5, 3)}; // 两次有参 CSample array3[2] = {3}; // 一次有参一次无参 CSample *array4 = new CSample[2]; delete[] array4; return 0; } 复制构造函数只有一个参数, 且参数是本类的引用 (或常量引用). 如果没有定义, 编译器会生成一个默认的复制构造函数. 如果定义了, 默认复制构造函数就不会生成.\n1 2 3 4 5 6 7 8 class Complex { private: double real; double imag; }; Complex c1; Complex c2(c1); // 默认复制构造函数 1 2 3 4 5 6 7 8 9 10 11 12 13 class Complex { public: double real; double imag; Complex() {} // 必须要写, 否则编译器不会生成默认构造函数 Complex(const Complex \u0026amp;c) { real = c.real; imag = c.imag; cout \u0026lt;\u0026lt; \u0026#34;Copy Constructor called\u0026#34;; } }; Complex c1; Complex c2(c1); // 自定义复制构造函数 复制构造函数的调用时机:\n用一个对象去初始化另一个对象.\n1 2 Complex c1; Complex c2(c1); 一个对象作为函数参数传递给一个非引用类型的参数.\n1 2 3 void func(Complex c); Complex c1; func(c1); 一个对象作为函数返回值返回.\n1 2 Complex func(); Complex c1 = func(); 注意: 对象之间的赋值操作, 不会调用复制构造函数.\n1 2 Complex c1, c2; c1 = c2; // 不会调用复制构造函数 考虑到对象作为函数参数会掉用复制构造函数, 为了避免不必要的开销, 可以使用引用传递.\n手动写复制构造函数的目的一般是为了实现深拷贝.\n转换构造函数的目的是实现类型的自动转换. 不以说明符 explicit 声明 {且可以用单个参数调用 (C++11 前)} 的构造函数被称为转换构造函数.\n1 2 3 4 5 6 7 8 9 10 11 12 class Complex { public: double real, imag; Complex(int i) { // 类型转换构造函数 real = i; imag = 0; } }; int main() { Complex c1 = 9; // 隐式调用, 转换成一个临时 Complex 对象 return 0; } 如果加了 explicit 关键字, 则只能显式调用.\n1 2 3 4 5 6 7 8 9 10 11 12 13 class Complex { public: double real, imag; explicit Complex(int i) { // 类型转换构造函数 real = i; imag = 0; } }; int main() { Complex c1 = 9; // 错误 Complex c2(9); // 正确 return 0; } 析构函数 析构函数是类的一个特殊成员函数, 名字由波浪号 ~ 加类名构成, 没有参数, 也没有返回值, 对象消亡时即自动被调用, 作用是释放对象所占用的资源.\n如果定义类时没写析构函数，则编译器生成缺省析构函数。缺省析构函数什么也不做. 如果定义了析构函数, 缺省析构函数就不会生成. 一个类只有一个析构函数, 不能重载.\n在数组生命周期结束时, 编译器会自动调用数组中每个元素的析构函数. delete 一个对象时, 会调用对象的析构函数. (注意, new 数组要用 delete[])\n1 2 3 4 5 Ctest *pTest; pTest = new Ctest; // 构造函数调用 delete pTest; // 析构函数调用 pTest = new Ctest[3]; // 构造函数调用 3 次 delete[] pTest; // 析构函数调用 3 次 this 指针 this 是一个指向对象本身的指针. 把 car.foo() 翻译成 C 就是 foo(\u0026amp;car)\n1 2 3 4 5 6 7 8 9 class A { int i; public: void hello() { cout \u0026lt;\u0026lt; \u0026#34;hello\u0026#34; \u0026lt;\u0026lt; endl; } }; int main() { A *p = NULL; p-\u0026gt;hello(); } 能运行且输出, 但是是未定义行为. 而且一旦 hello() 中用到了 this, 就会出错.\n非静态成员函数中可以直接使用 this 来代表指向该函数作用的对象的指针。\n1 2 3 4 5 6 7 8 9 10 11 12 13 class Complex { public: double real, imag; void print() { cout \u0026lt;\u0026lt; real \u0026lt;\u0026lt; \u0026#34;,\u0026#34; \u0026lt;\u0026lt; imag; } Complex(double r, double i) : real(r), imag(i) {} Complex addOne() { this-\u0026gt;real++; // 等价于 real++; this-\u0026gt;print(); // 等价于 print() return *this; // 返回对象本身 } }; 静态成员 静态成员即加了 static 关键字的成员.\n静态成员变量是类的所有对象共享的. sizeof 不包括静态成员变量. 本质是全局变量. 静态成员函数是类的所有对象共享的函数, 静态成员函数只能访问静态成员变量和静态成员函数, 不能访问普通成员变量和普通成员函数, 也不可以用 this 指针. 本质是全局函数.\n访问静态成员可以不通过对象访问. 类名::静态成员名.\n1 2 int Rectangle::edges = 4; Rectangle::printTotal(); 即使类的对象不存在, 静态成员变量也存在.\n","date":"2025-02-19T00:00:00Z","permalink":"https://LeoDreamer2004.github.io/p/program-practice/class-and-object/","title":"程序设计实习(1) —— 类和对象"},{"content":" 导航\n博客页面 课件 程序设计实习(1) —— 类和对象 课件链接1 课件链接2 课件链接3 ","date":"2025-02-18T00:00:00Z","permalink":"https://LeoDreamer2004.github.io/p/program-practice/","title":"程序设计实习"},{"content":" 本节课件链接\n基础数学工具 定义\n随机变量 $X$ 的 期望 $E[X]$ 定义为\n$$ E[X] = \\sum_{x} x \\cdot P(X=x) $$随机变量 $X$ 的 方差 $\\text{Var}(X)$ 定义为\n$$ \\text{Var}(X) = E[(X - E[X])^2] $$标准差 $\\sigma(X)$ 定义为\n$$ \\sigma(X) = \\sqrt{\\text{Var}(X)} $$ 定理Markov 不等式\n设 $X$ 是一个非负随机变量, 期望存在, 那么对于任意 $t \u0026gt; 0$ 有\n$$ P(X \\geq t) \\leq \\frac{E[X]}{t} $$ 定理Chebyshev 不等式\n设 $X$ 是一个随机变量, 期望和方差都存在, 那么对于任意 $t \u0026gt; 0$ 有\n$$ P(|X - E[X]| \\geq t) \\leq \\frac{\\text{Var}(X)}{t^2} $$ 定义\n随机变量 $X$ 和 $Y$ 的 协方差 $\\text{Cov}(X, Y)$ 定义为\n$$ \\text{Cov}(X, Y) = E[(X - E[X])(Y - E[Y])] $$如果 $\\text{Cov}(X, Y) = 0$, 则称 $X$ 和 $Y$ 不相关.\n协方差具有对称性, 双线性.\n定义\n随机向量 $X=(X_1, X_2, \\ldots, X_n)$ 的 协方差矩阵 $C(X)$ 定义为\n$$ C(X) = E[(X - E[X])(X - E[X])^T] = (\\text{Cov}(X_i, X_j))_{ij} $$ 定义\nGauss 分布 (正态分布) 的概率密度函数为\n$$ f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp(-\\frac{(x-\\mu)^2}{2\\sigma^2}) $$Laplace 分布 的概率密度函数为\n$$ f(x) = \\frac{1}{2b} \\exp(-\\frac{|x-\\mu|}{b}) $$ 最优化问题\n$$ \\begin{aligned} \u0026 \\min f(x) \\\\ \\text{s.t. } \u0026 c_i(x) \\leq 0, i = 1, 2, \\dots, k \\\\ \u0026 h_j(x) = 0, j = 1, 2, \\dots, l \\end{aligned} $$构造 Lagrange 函数\n$$ L(x, \\alpha, \\beta) = f(x) + \\sum_{i=1}^{k} \\alpha_i c_i(x) + \\sum_{j=1}^{l} \\beta_j h_j(x) $$引入 Karush-Kuhn-Tucker (KKT) 条件\n$$ \\begin{aligned} \u0026 \\nabla_x L(x, \\alpha, \\beta) = 0 \\\\ \u0026 c_i(x) \\leq 0, i = 1, 2, \\dots, k \\\\ \u0026 h_j(x) = 0, j = 1, 2, \\dots, l \\\\ \u0026 \\alpha_i c_i(x) = 0, i = 1, 2, \\dots, k \\\\ \u0026 \\alpha_i \\geq 0, i = 1, 2, \\dots, k \\end{aligned} $$基本概念和术语 定义\n监督学习: 基于标记数据 $T=\\{ (x_i,y_i) \\}_{i=1}^N$, 学习一个从输入空间到输出空间的映射 $f: \\mathcal{X} \\mapsto \\mathcal{Y}$. 利用此对未见数据进行预测. 通常分为 回归 和 分类 两类.\n无监督学习: 基于未标记数据 $T=\\{ x_i \\}_{i=1}^N$, 发现其中隐含的知识模式. 聚类 是典型的无监督学习任务.\n半监督学习: 既有标记数据又有未标记数据 (通常占比较大).\n强化学习: 通过观察环境的反馈, 学习如何选择动作以获得最大的奖励.\n模型评估与选择 损失函数 模型基于算法按照一定策略给出假设 $h \\in \\mathcal{H}$, 通过 损失函数 $L(h(x), y)$ 衡量假设的好坏.\n0-1 损失函数: $$L(h(x), y) = \\mathbb{I}(h(x) \\neq y) = \\begin{cases} 0, \u0026 h(x) = y \\\\ 1, \u0026 h(x) \\neq y \\end{cases}$$ 平方损失函数: $$L(h(x), y) = (h(x) - y)^2$$平均损失 $R(h) = E_{x \\sim D} [L(h(x), y)]$ 称为 泛化误差.\n容易验证, 对于 0-1 损失函数, 准确率 $a = 1-R(h)$.\n二分类 对于二分类问题, 样本预测结果有四种情况:\n真正例 (True Positive, TP): 预测为正例, 实际为正例. 假正例 (False Positive, FP): 预测为正例, 实际为负例. 真负例 (True Negative, TN): 预测为负例, 实际为负例. 假负例 (False Negative, FN): 预测为负例, 实际为正例. 由此引入\n准确率(查准率): $P = \\frac{TP}{TP+FP}$. 召回率(查全率): $R = \\frac{TP}{TP+FN}$. $F_1$ 度量: 考虑到二者抵触, 引入调和均值 $F_1 = \\frac{2PR}{P+R}$. 过拟合和正则化 为了防止由于模型过于复杂而导致的过拟合, 可以通过 正则化 方法来限制模型的复杂度.\n$$ \\min \\sum_{i=1}^{N} L(h(x_i), y_i) + \\lambda J(h) $$其中 $J(h)$ 是随着模型复杂度增加而增加的函数. $\\lambda$ 是正则化参数.\n怎么选取合适的 $\\lambda$ ? 一般是先给出若干候选, 在验证集上进行评估, 选取泛化误差最小的.\n数据集划分 一般将数据集划分为 训练集 $T$ 和 测试(验证)集 $T^\\prime$.\n留出法 (hold-out): 分层无放回地随机采样. 也叫简单交叉验证. $k$ 折交叉验证 ($k$-fold cross validation): 将数据集分为 $k$ 个大小相等的子集, 每次取其中一个作为验证集, 其余作为训练集, 最后以这 $k$ 次的平均误差作为泛化误差的估计. 当 $k=|D|$ 时称为留一 (leave-one-out) 验证法. 自助法 (bootstrapping): 从数据集中有放回地采样 $|D|$ 个数据作为训练集, 没抽中的作为验证集. 因而训练集 $T$ 和原始数据集 $D$ 的分布未必一致, 对数据分布敏感的模型不适用. 偏差-方差分解 为什么泛化误差会随着模型复杂度的增加而先减小后增大?\n定义\n偏差 (bias): 模型预测值的期望与真实值之间的差异. 体现了模型的拟合能力.\n$$\\text{Bias}(x) = E_T[h_T(x)-c(x)] = \\bar{h}(x) - c(x)$$方差 (variance): 模型预测值的方差. 体现了模型的对数据扰动的稳定性.\n$$\\text{Var}(x) = E[(h(x) - \\bar{h}(x))^2]$$ 现在对泛化误差进行分解:\n$$ \\begin{aligned} R(h) \u0026= E_T[(h_T(x) - c(x))^2] \\\\ \u0026= E_T[h_T^2(x) - 2h_T(x)c(x) + c^2(x)] \\\\ \u0026= E_T[h_T^2(x)] - 2c(x)E_T[h_T(x)] + c^2(x) \\\\ \u0026= E_T[h_T^2(x)] - \\bar{h}^2(x) + \\bar{h}^2(x) - 2\\bar{h}(x)c(x) + c^2(x) \\\\ \u0026= E_T[(h_T(x) - \\bar{h}(x))^2] + (\\bar{h}(x) - c(x))^2 \\\\ \u0026= \\text{Var}(x) + \\text{Bias}^2(x) \\end{aligned} $$当然, 由于噪声存在, $y$ 未必一定等于 $c(x)$, 不妨设 $y=c(x)+\\varepsilon$, 其中 $\\varepsilon \\sim \\Epsilon$ 期望为 $0$. 可以证明\n定理偏差-方差分解\n$$ E_{T \\sim D^{|T|}, \\varepsilon \\sim \\Epsilon} [(h_T(x)-y)^2] = \\text{Bias}^2(x) + \\text{Var}(x) + E[\\varepsilon^2] $$即泛化误差可以分解为偏差、方差和噪声三部分.\n起初, 模型较为简单, 偏差在泛化误差起主导作用. 随着模型复杂度的增加, 拟合能力增强, 偏差减小, 但带来过拟合风险, 算法对数据扰动敏感, 方差增大. 方差占比逐渐增大, 最终导致泛化误差增大.\n","date":"2025-02-18T00:00:00Z","permalink":"https://LeoDreamer2004.github.io/p/machine-learning/intro/","title":"机器学习基础(1) —— 概述"},{"content":" 导航\n博客页面 课件 机器学习基础(1) —— 概述 课件链接 ","date":"2025-02-17T00:00:00Z","permalink":"https://LeoDreamer2004.github.io/p/machine-learning/","title":"机器学习基础"},{"content":" 本节课件链接\n凸优化 凸问题的可行集都是凸集.\n定理\n凸优化问题的任意局部极小点都是全局最优点.\n证明\n假设 $x$ 是局部极小, $y$ 全局最优且 $f(y) \u0026lt; f(x)$.\n考虑 $z = \\theta x + (1-\\theta) y$, 则由于 $z$ 是可行点的凸组合, 也是可行点. 由于 $f$ 是凸函数, 有\n$$ f(z) \\leq \\theta f(x) + (1-\\theta) f(y) \u003c f(x) $$取 $\\theta \\to 1$, 则 $f(z) \\to f(x)$, 与局部最小性矛盾.\n线性规划 所谓 线性规划(LP) 问题是指目标函数和约束条件都是线性的优化问题. 一般形式如下:\n$$ \\begin{aligned} \\min \\quad \u0026 c^T x \\\\ \\text{s.t.} \\quad \u0026 Ax = b \\\\ \u0026 Gx \\le e \\end{aligned} $$$\\ell_1$ 和 $\\ell_\\infty$ 范数实际上也是线性的.\n凸多边形\n$$P = \\{ x \\mid a_i^Tx \\le b_i \\}$$的切比雪夫中心是最大半径内切球的中心. 代入得\n$$ \\sup \\{a_i^T (x_c + u) \\mid \\Vert u \\Vert_2 \\le r \\} = a_i^Tx_c + r \\Vert a_i \\Vert_2 \\le b_i $$这也变成了一个线性规划问题.\n二次规划 二次规划问题是指目标函数是二次的的优化问题.\n例如, 对于线性约束条件的问题, 一般形式如下:\n$$ \\begin{aligned} \\min \\quad \u0026 \\frac{1}{2} x^T P x + q^T x + r \\\\ \\text{s.t.} \\quad \u0026 Ax = b \\\\ \u0026 Gx \\le e \\end{aligned} $$也有 带二次约束的二次规划 (QCQP).\n我们归结为 二次锥规划 (SOCP):\n$$ \\begin{aligned} \\min \\quad \u0026 f^T x \\\\ \\text{s.t.} \\quad \u0026 \\Vert A_i x + b_i \\Vert_2 \\le c_i^T x + d_i, \\quad i = 1, \\ldots, m \\\\ \u0026 Fx = g \\end{aligned} $$最小范数问题: 令 $\\bar{v_i} = A_ix+b_i \\in \\mathbb{R}^{n_i}$, 则\n$\\min_x \\sum_i \\Vert \\bar{v_i} \\Vert_2$ 等价于 $$ \\begin{aligned} \\min \\quad \u0026 \\sum_i v_{i0} \\\\ \\text{s.t.} \\quad \u0026\\bar{v_i} = A_i x + b_i \\\\ \u0026(v_{i0}, \\bar{v_i}) \\succeq_\\mathcal{Q} 0 \\end{aligned} $$其中 $\\mathcal{Q}$ 是二次锥.\n最大 $k$ 范数和问题: 设 $\\Vert \\bar{v_[i]} \\Vert$ 是 $\\bar{v_i}$ 的非递增方式的排序. 则 $\\min_x \\sum_{i=1}^m \\Vert \\bar{v_[i]} \\Vert$ 等价于\n$$ \\begin{aligned} \\min \\quad \u0026 \\sum_{i=1}^m u_i + kt \\\\ \\text{s.t.} \\quad \u0026 \\bar{v_i} = A_i x + b_i \\\\ \u0026 \\Vert \\bar{v_i} \\Vert \\le u_i + t \\\\ \u0026 u_i \\ge 0 \\end{aligned} $$","date":"2025-02-15T00:00:00Z","permalink":"https://LeoDreamer2004.github.io/p/opt-method/opt-problem/","title":"最优化方法(4) —— 优化问题"},{"content":" 本节课件链接\n基本线性代数知识 定义\n给定函数 $f: \\mathbb{R}^n \\mapsto \\mathbb{R}$, 且 $f$ 在 $x$ 一个邻域内有定义, 若存在 $g \\in \\mathbb{R}^n$, 使得\n$$ \\lim_{p \\to 0} \\frac{f(x+p)-f(x)-g^Tp}{\\Vert p \\Vert} = 0 $$其中 $\\Vert \\cdot \\Vert$ 是向量范数, 则称 $f$ 在 $x$ 处 可微. 此时, $g$ 称为 $f$ 在 $x$ 处的 梯度, 记为 $\\nabla f(x)$.\n显然, 如果梯度存在, 令 $p = \\varepsilon e_i$, 易得\n$$ \\nabla f(x) = \\left( \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_n} \\right) $$ 定义\n如果函数 $f(x): \\mathbb{R}^n \\mapsto \\mathbb{R}$ 在点 $x$ 处的二阶偏导数 $\\dfrac{\\partial^2 f}{\\partial x_i \\partial x_j}$ 存在, 则称 $f$ 在 $x$ 处 二次可微. 此时, $n \\times n$ 矩阵\n$$ \\nabla^2 f(x) = \\begin{pmatrix} \\dfrac{\\partial^2 f}{\\partial x_1^2} \u0026 \\dfrac{\\partial^2 f}{\\partial x_1 \\partial x_2} \u0026 \\cdots \u0026 \\dfrac{\\partial^2 f}{\\partial x_1 \\partial x_n} \\\\ \\dfrac{\\partial^2 f}{\\partial x_2 \\partial x_1} \u0026 \\dfrac{\\partial^2 f}{\\partial x_2^2} \u0026 \\cdots \u0026 \\dfrac{\\partial^2 f}{\\partial x_2 \\partial x_n} \\\\ \\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\ \\dfrac{\\partial^2 f}{\\partial x_n \\partial x_1} \u0026 \\dfrac{\\partial^2 f}{\\partial x_n \\partial x_2} \u0026 \\cdots \u0026 \\dfrac{\\partial^2 f}{\\partial x_n^2} \\end{pmatrix} $$称为 $f$ 在 $x$ 处的 Hessian 矩阵. 若 $\\nabla^2 f(x)$ 在 $D$ 上连续, 则称 $f$ 在 $D$ 上 二次连续可微.\n可以证明, 若 $f$ 在 $D$ 上二次连续可微, 则 $\\nabla^2 f(x)$ 为对称矩阵.\n多元函数的梯度可以推广到变量是矩阵的情形.\n定义\n给定函数 $f: \\mathbb{R}^{m \\times n} \\mapsto \\mathbb{R}$, 且 $f$ 在 $X$ 一个邻域内有定义, 若存在 $G \\in \\mathbb{R}^{m \\times n}$, 使得\n$$ \\lim_{V \\to 0} \\frac{f(X+V)-f(X)-\\langle G, V \\rangle}{\\Vert V \\Vert} = 0 $$其中 $\\Vert \\cdot \\Vert$ 是矩阵范数, 则称 $f$ 在 $X$ 处 (Fréchet)可微. 此时, $G$ 称为 $f$ 在 $X$ 处的 梯度, 记为 $\\nabla f(X)$.\n矩阵的可微有另一种较为简单常用的定义.\n定义\n给定函数 $f: \\mathbb{R}^{m \\times n} \\mapsto \\mathbb{R}$, 若存在矩阵 $G \\in \\mathbb{R}^{m \\times n}$, 使得\n$$ \\lim_{t \\to 0} \\frac{f(X+tV)-f(X)}{t} = \\langle G, V \\rangle $$则称 $f$ 在 $X$ 处 (Gâteaux)可微.\n例如:\n$f(X) = \\text{tr}(AX^TB)$, 此时 $\\nabla f(X) = BA$.\n$f(X, Y)=\\frac{1}{2} \\Vert XY-A \\Vert_F^2$. 此时\n$$ \\begin{aligned} \u0026f(X,Y+tV)-f(X,Y) \\\\ \u0026= \\frac{1}{2} \\Vert X(Y+tV)-A \\Vert_F^2 - \\frac{1}{2} \\Vert XY-A \\Vert_F^2 \\\\ \u0026= \\frac{1}{2} \\Vert XY - A + tVX \\Vert_F^2 - \\frac{1}{2} \\Vert XY - A \\Vert_F^2 \\\\ \u0026= \\frac{1}{2} \\Vert tVX \\Vert_F^2 + \\langle XY-A, tVX \\rangle \\\\ \u0026= t \\langle X^T(XY-A), V \\rangle + o(t) \\end{aligned} $$所以 $\\frac{\\partial f}{\\partial Y} = X^T(XY-A)$, 类似地, $\\frac{\\partial f}{\\partial X} = (XY-A)Y^T$.\n$f(X)=\\ln\\text{det}(X)$, $X$ 为正定矩阵. 此时\n$$ \\begin{aligned} \u0026f(X+tV)-f(X) \\\\ \u0026= \\ln\\text{det}(X+tV) - \\ln\\text{det}(X) \\\\ \u0026= \\ln\\text{det}(I+tX^{-1/2}VX^{-1/2}) \\end{aligned} $$考虑 $X^{-1/2}VX^{-1/2}$ 的特征值 $\\lambda_i$, 则由特征值之和为迹, 有\n$$ \\begin{aligned} \u0026= \\ln\\text{det}\\prod_{i=1}^n (1+t\\lambda_i) \\\\ \u0026= \\sum_{i=1}^n \\ln(1+t\\lambda_i) \\\\ \u0026= \\sum_{i=1}^n t\\lambda_i + o(t) \\\\ \u0026= t\\text{tr}(X^{-1/2}VX^{-1/2}) + o(t) \\\\ \u0026= t\\text{tr}(X^{-1}V) + o(t) \\\\ \u0026= t\\langle X^{-T}, V \\rangle + o(t) \\end{aligned} $$所以 $\\nabla f(X) = X^{-T}$.\n定义\n广义实数 是一种扩充实数域的数, 记为 $\\bar{\\mathbb{R}} = \\mathbb{R} \\cup \\{ \\pm \\infty \\}$. 映射 $f: \\mathbb{R}^n \\mapsto \\bar{\\mathbb{R}}$ 称为 广义实值函数.\n定义\n给定广义实值函数 $f$ 和非空集合 $X$. 如果存在 $x \\in X$ 使得 $f(x) \u0026lt; +\\infty$, 并且对任意的 $x \\in X$, 都有 $f(x) \u0026gt; -\\infty$, 那么称函数 $f$ 关于集合 $X$ 是 适当的．\n定义\n对于广义实值函数 $f: \\mathbb{R}^n \\mapsto \\bar{\\mathbb{R}}$,\n$C_\\alpha = \\{x \\mid f(x) \\le \\alpha \\}$ 称为 $f$ 的 $\\alpha$-下水平集. $\\text{epi} f = \\{ (x, t) \\mid f(x) \\le t \\}$ 称为 $f$ 的 上方图. 若 $\\text{epi} f$ 为闭集, 则称 $f$ 为闭函数. 若对任意的 $x \\in \\mathbb{R}^n$, 有 $\\liminf_{y \\to x} f(y) \\ge f(x)$, 则称 $f$ 为 下半连续函数. 定理\n对于广义实值函数 $f$, 以下命题等价:\n$f(x)$ 的任意 $\\alpha$-下水平集都是闭集; $f(x)$ 是下半连续的; $f(x)$ 是闭函数. 证明\n(1) $\\Rightarrow$ (2): 反证, 假设 $x_k \\to \\bar{x}$ 但 $\\liminf_{k \\to \\infty} f(x_k) \u0026lt; f(\\bar{x})$. 取 $t$ 介于二者之间.\n考虑到 $\\liminf_{k \\to \\infty} f(x_k) \u0026lt; t$, 则有无穷多 $x_k$ 使得 $f(x_k) \\le t$, 即这些 $x_k$ 在 $C_t$ 中. 由于 $C_t$ 是闭集, 则 $\\bar{x} \\in C_t$, 即 $f(\\bar{x}) \\le t$, 矛盾.\n(2) $\\Rightarrow$ (3): 考虑 $(x_k,y_k) \\in \\text{epi} f \\to (\\bar{x},\\bar{y})$, 由于 $f$ 下半连续, 则\n$$ f(\\bar{x}) \\le \\liminf_{k \\to \\infty} f(x_k) = \\liminf_{k \\to \\infty} y_k = \\bar{y} $$即 $(\\bar{x}, \\bar{y}) \\in \\text{epi} f$.\n(3) $\\Rightarrow$ (1): 考虑 $x_k \\in C_\\alpha \\to \\bar{x}$, 则 $(x_k, \\alpha) \\in \\text{epi} f \\to (\\bar{x}, \\alpha)$, 所以 $(\\bar{x}, \\alpha) \\in \\text{epi} f$, 即 $f(\\bar{x}) \\le \\alpha$, 所以 $\\bar{x} \\in C_\\alpha$.\n适当闭函数的和, 复合, 逐点上确界仍然是闭函数.\n凸函数 定义\n适当函数 $f: \\mathbb{R}^n \\mapsto \\mathbb{R}$ 称为 凸函数, 如果 $\\text{dom} f$ 是凸集, 且对任意的 $x, y \\in \\text{dom} f$ 和 $\\theta \\in [0,1]$, 有\n$$ f(\\theta x + (1-\\theta)y) \\le \\theta f(x) + (1-\\theta)f(y) $$ 易知仿射函数既是凸函数又是凹函数. 所有的范数都是凸函数.\n定义\n若存在常数 $m \u0026gt; 0$, 使得 $g(x) = f(x) - \\frac{m}{2} \\Vert x \\Vert^2$ 是凸函数, 则称 $f$ 是 强凸函数, $m$ 称为 强凸参数.\n定理凸函数判定定理\n适当函数 $f: \\mathbb{R}^n \\mapsto \\mathbb{R}$ 是凸函数的充要条件是, 对任意的 $x \\in \\text{dom} f$, 函数 $g: \\mathbb{R} \\mapsto \\mathbb{R}$ 是凸函数, 其中\n$$g(t) = f(x+tv), \\quad \\text{dom}g = \\{ t \\mid x + tv \\in \\text{dom} f \\}$$证明\n利用定义是容易的, 略去.\n定理一阶条件\n对于定义在凸集上的可微函数 $f$, $f$ 是凸函数当且仅当\n$$ f(y) \\ge f(x) + \\nabla f(x)^T(y-x), \\quad \\forall x, y \\in \\text{dom} f $$证明\n必要性: 设 $f$ 凸, 则 $\\forall x, y \\in \\text{dom} f, t \\in [0,1]$, 有\n$$tf(y)+(1-t)f(x) \\ge f(x+t(y-x))$$令 $t \\to 0$, 即\n$$f(y)-f(x) \\ge \\frac{f(x+t(y-x))-f(x)}{t} \\to \\nabla f(x)^T(y-x)$$充分性: $\\forall x, y \\in \\text{dom}f, t\\in (0,1)$, 取 $z = tx+(1-t)y$, 则\n$$ \\begin{aligned} f(x) \u0026\\ge f(z) + \\nabla f(z)^T(x-z) \\\\ f(y) \u0026\\ge f(z) + \\nabla f(z)^T(y-z) \\end{aligned} $$一式乘以 $t$, 二式乘以 $1-t$, 相加即得.\n定理梯度单调性\n设 $f$ 为可微函数, 则 $f$ 为凸函数当且仅当 $\\text{dom} f$ 为凸集且 $\\nabla f$ 为单调映射.\n$$(\\nabla f(x) - \\nabla f(y))^T(x-y) \\ge 0$$证明\n必要性: 根据一阶条件, 有\n$$ \\begin{aligned} f(y) \u0026\\ge f(x) + \\nabla f(x)^T(y-x) \\\\ f(x) \u0026\\ge f(y) + \\nabla f(y)^T(x-y) \\end{aligned} $$相加即可.\n充分性: 考虑 $g(t)=f(x+t(y-x))$, 则 $g^\\prime(t)=\\nabla f(x+t(y-x))^T (y-x)$, 从而 $g^\\prime (t) \\ge g^\\prime (0)$.\n$$ \\begin{aligned} f(y) \u0026= g(1) = g(0) + \\int_{0}^1 g^\\prime(t) dt \\\\ \u0026\\ge g(0) + \\int_{0}^1 g^\\prime(0) dt = g(0) + g^\\prime(0) \\\\ \u0026= f(x) + \\nabla f(x)^T(y-x) \\end{aligned} $$ 定理\n函数 $f(x)$ 是凸函数当且仅当 $\\text{epi}f$ 是凸集.\n证明\n用定义显然, 略去.\n定理二阶条件\n设 $f$ 为定义在凸集上的二阶连续可微函数, $f$ 是凸函数当且仅当 $\\nabla^2 f(x) \\succeq 0, \\forall x \\in \\text{dom} f$. 若不取等, 则为严格凸函数.\n证明\n必要性: 反设 $f(x)$ 在 $x$ 处 $\\nabla^2 f(x) \\prec 0$, 则存在 $v \\in \\mathbb{R}^n$, 使得 $v^T \\nabla^2 f(x) v \u0026lt; 0$, 考虑 Peano 余项\n$$ f(x+tv)=f(x)+t\\nabla f(x)^Tv+\\frac{t^2}{2}v^T\\nabla^2 f(x+tv)v + o(t^2) $$取 $t$ 充分小,\n$$ \\frac{f(x+tv)-f(x)-t\\nabla f(x)^T v}{t^2}=\\frac{1}{2}v^T\\nabla^2 f(x+tv)v + o(1) \u003c 0 $$这和一阶条件矛盾.\n充分性: 对于任意的 $x, y \\in \\text{dom} f$, 有\n$$ \\begin{aligned} f(y) \u0026= f(x)+\\nabla f(x)^T(y-x)+\\frac{1}{2}(y-x)^T\\nabla^2 f(z)(y-x) \\\\ \u0026\\ge f(x)+\\nabla f(x)^T(y-x) \\end{aligned} $$由一阶条件, $f$ 为凸函数.\n保凸运算 下面举一些重要的例子.\n逐点取上界: 若对每个 $y \\in A$, $f(x,y)$ 都是关于 $x$ 的凸函数, 则\n$$g(x)=\\sup_{y \\in A} f(x,y)$$也是凸函数.\n$C$ 的支撑函数 $f(x)=\\sup_{y \\in C} y^Tx$ 是凸函数. $C$ 到 $x$ 的最远距离 $f(x)=\\sup_{y \\in C} \\Vert x-y \\Vert$ 是凸函数. 对称阵 $X \\in \\mathbb{S}^n$ 的最大特征值 $\\lambda_{\\max}(X)=\\sup_{\\Vert x \\Vert=1} x^TXx$ 是凸函数. 标量函数的复合: 若 $g: \\mathbb{R}^n \\mapsto \\mathbb{R}$ 是凸函数, $h: \\mathbb{R} \\mapsto \\mathbb{R}$ 是单调不减的凸函数, 则\n$$f(x) = h(g(x))$$也是凸函数. 凹同理.\n如果 $g$ 凸, 则 $f(x) = \\exp(g(x))$ 也是凸函数. 如果 $g$ 凹, 则 $f(x) = 1/g(x)$ 也是凸函数. 取下确界: 若 $f(x, y)$ 关于 $(x, y)$ 整体是凸函数, $C$ 是凸集, 则\n$$g(x) = \\inf_{y \\in C} f(x, y)$$也是凸函数.\n凸集 $C$ 到 $x$ 的距离 $f(x)=\\inf_{y \\in C} \\Vert x-y \\Vert$ 是凸函数. 透视函数: 若 $f: \\mathbb{R}^{n} \\mapsto \\mathbb{R}$ 是凸函数, 则\n$$g(x, t) = tf(x/t), \\quad \\text{dom} g = \\{ (x, t) \\mid x / t \\in \\text{dom} f, t \u003e 0 \\}$$也是凸函数.\n相对熵函数 $g(x,t)=t\\log t-t\\log x$ 是凸函数. 若 $f$ 凸, 则 $g(x)=(c^T+d)f((Ax+b)/(c^T+d))$ 也是凸函数. 共轭函数: 任意适当函数 $f$ 的共轭函数\n$$f^\\ast(y)=\\sup_{x \\in \\text{dom} f} (\\langle x, y \\rangle - f(x))$$是凸函数.\n凸函数的推广 定义\n$f: \\mathbb{R}^n \\mapsto \\mathbb{R}$ 称为 拟凸的, 如果 $\\text{dom} f$ 是凸集, 且对任意 $\\alpha$, 下水平集 $C_\\alpha$ 是凸集.\n若 $f$ 是拟凸的, 则称 $-f$ 是 拟凹的. 若 $f$ 既是拟凸又是拟凹的, 则称 $f$ 是 拟线性的.\n注意: 拟凸函数的和不一定是拟凸函数.\n定理\n拟凸函数满足类 Jenson 不等式: 对拟凸函数 $f$ 和 $\\forall x, y \\in \\text{dom} f, \\theta \\in [0,1]$, 有 $$f(\\theta x + (1-\\theta)y) \\le \\max\\left\\{f(x),f(y)\\right\\}$$ 拟凸函数满足一阶条件: 定义在凸集上的可微函数 $f$ 拟凸当且仅当 $$f(y) \\le f(x) \\Rightarrow \\nabla f(x)^T(y-x) \\le 0$$ 定义\n如果正值函数 $f$ 满足 $\\log f$ 是凸函数, 则 $f$ 称为 对数凸函数; 若为凹函数, 则 $f$ 称为 对数凹函数.\n例如, 正态分布\n$$f(x) = \\frac{1}{\\sqrt{(2\\pi)^n \\text{det} \\Sigma}} \\exp\\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)$$是对数凹函数.\n对数凹函数的乘积, 积分都是对数凹的, 但加和不一定是对数凹的.\n在广义不等式下, 也可以定义凸凹性.\n定义\n$$f(\\theta x+(1-\\theta)y \\preceq_K \\theta f(x)+(1-\\theta)f(y))$$ 对任意 $x,y \\in \\text{dom} f, 0 \\le \\theta \\le 1$ 成立.\n例如, $f: \\mathbb{S}^m \\mapsto \\mathbb{S}^m$, $f(X)=X^2$ 是 $\\mathbb{S}^m_+$-凸函数. 这点利用 $z^TX^2z=\\Vert Xz \\Vert^2$ 是关于 $X$ 的凸函数即可得知.\n","date":"2025-01-25T00:00:00Z","permalink":"https://LeoDreamer2004.github.io/p/opt-method/convex-function/","title":"最优化方法(3) —— 凸函数"},{"content":" 本节课件链接\n范数 定义\n记号 $\\Vert \\cdot \\Vert: \\mathbb{R}^n \\mapsto \\mathbb{R}$ 称为 向量范数, 若满足:\n正定性: $\\Vert x \\Vert \\geq 0$, 且 $\\Vert x \\Vert = 0 \\Leftrightarrow x = 0$; 齐次性: $\\Vert \\alpha x \\Vert = \\vert \\alpha \\vert \\Vert x \\Vert$; 三角不等式: $\\Vert x + y \\Vert \\leq \\Vert x \\Vert + \\Vert y \\Vert$. $\\ell_p$ 范数是最常见的向量范数\n$$ \\Vert x \\Vert_p = \\left( \\sum_{i=1}^n \\vert x_i \\vert^p \\right) ^{\\frac{1}{p}} $$特别地, 当 $p = \\infty$ 时, $\\Vert x \\Vert_\\infty = \\max_i \\vert x_i \\vert$.\n向量范数可以自然地推广到矩阵范数. 常见的矩阵范数有:\n和范数: $\\Vert A \\Vert_1 = \\sum_{i,j} \\vert A_{ij} \\vert$; Frobenius 范数: $\\Vert A \\Vert_F = \\sqrt{\\sum_{i,j} A_{ij} ^2} = \\sqrt{\\text{tr}(A^T A)}$; 算子范数: $\\Vert A \\Vert_{(m,n)}=\\max_{\\Vert x \\Vert_n = 1} \\Vert Ax \\Vert_m$. 特别地, 当 $m = n = p$ 时: $p=1$ 时, $\\Vert A \\Vert_{p=1} = \\max_j \\sum_i \\vert A_{ij} \\vert$; $p=2$ 时, $\\Vert A \\Vert_{p=2} = \\sqrt{\\lambda_{\\max}(A^T A)}$, 亦称为 谱范数. $p=\\infty$ 时, $\\Vert A \\Vert_{p=\\infty} = \\max_i \\sum_j \\vert A_{ij} \\vert$. 核范数: $\\Vert A \\Vert_\\ast = \\sum_i \\sigma_i$, 其中 $\\sigma_i$ 为 $A$ 的奇异值. 定理 柯西不等式\n$$\\vert \\langle X, Y \\rangle \\vert \\leq \\Vert X \\Vert \\Vert Y \\Vert$$等号成立当且仅当 $X$ 与 $Y$ 线性相关.\n凸集 定义\n如果对于任意 $x, y \\in C$ 和 $\\theta \\in \\mathbb{R}$, 都有 $\\theta x + (1-\\theta) y \\in C$, 则称 $C$ 为 仿射集.\n如果对于任意 $x, y \\in C$ 和 $\\theta \\in [0, 1]$, 都有 $\\theta x + (1-\\theta) y \\in C$, 则称 $C$ 为 凸集.\n换言之, 仿射集要求过任意两点的直线都在集合内, 而凸集要求过任意两点的线段都在集合内. 显然, 仿射集都是凸集. 线性方程组的解集是一个仿射集, 而线性规划问题的可行域是一个凸集. 可以证明, 仿射集均可表示为某个线性方程组的解集.\n定理\n若 $S$ 是凸集, 则 $kS = \\left\\{ ks \\mid k \\in \\mathbb{R}, s \\in S \\right\\}$ 也是凸集; 若 $S, T$ 是凸集, 则 $S + T = \\left\\{ s + t \\mid s \\in S, t \\in T \\right\\}$ 也是凸集; 若 $S, T$ 是凸集, 则 $S \\cap T$ 也是凸集. 凸集的内部和闭包均为凸集. 可以证明, 任意多个凸集的交集仍为凸集.\n定义\n形如 $x=\\theta_1x_1+\\theta_2x_2+\\cdots+\\theta_kx_k$, 其中 $\\theta_i \\geq 0$ 且 $\\sum_i \\theta_i = 1$, 的表达式称为 $x$ 的 凸组合. 集合 $S$ 的所有点的凸组合构成的集合称为 $S$ 的 凸包, 记为 $\\text{conv}(S)$.\n定理\n若 $\\text{conv} S \\subseteq S$, 则 $S$ 为凸集, 反之亦然.\n证明\n先证明正方向. 对任意 $x,y \\in S, \\theta \\in [0,1]$, 有 $\\theta x + (1-\\theta) y \\in \\text{conv} S \\subseteq S$, 故 $S$ 为凸集.\n再证明反方向, 对凸组合的维数 $k$ 采用数学归纳法证明之.\n若 $k=1$, 显然成立. 假设对于 $k-1$ 成立, 则对于 $k$, 考虑\n$$ \\begin{aligned} x \u0026= \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_k x_k \\\\ \u0026= (1-\\theta_k)\\left(\\frac{\\theta_1}{1-\\theta_k} x_1 + \\frac{\\theta_2}{1-\\theta_k} x_2 + \\cdots + \\frac{\\theta_{k-1}}{1-\\theta_k} x_{k-1}\\right) + \\theta_k x_k \\end{aligned} $$前面大括号内的表达式为 $k-1$ 个凸组合, 故在 $S$ 中. 于是 $x$ 又成为两个点的凸组合, 由于 $S$ 为凸集, 故 $x \\in S$. 则 $\\text{conv} S \\subseteq S$.\n定理\n$\\text{conv}S$ 是包含 $S$ 的最小凸集; $\\text{conv}S$ 是所有包含 $S$ 的凸集的交集. 证明\n显然第一个是第二个的推论, 只证明第二个.\n已知凸集的交是凸集, 从而所有包含 $S$ 的凸集的交集 $X$ 是凸集. 且 $\\text{conv} S$ 是包含 $S$ 的凸集, 则 $X \\subseteq \\text{conv} S$.\n另一方面, $S \\subseteq X$, 则 $\\text{conv} S \\subseteq \\text{conv}X$, 而 $X$ 是凸集, 则 $\\text{conv}X = X$, 即 $\\text{conv}S \\subseteq X$. 综上, $\\text{conv}S = X$.\n仿照凸组合和凸包, 也可以定义仿射组合和仿射包 $\\text{affine} S$, 不再赘述.\n定义\n形如 $x=\\theta_1x_1+\\theta_2x_2+\\cdots+\\theta_kx_k$, 其中 $\\theta_i \\geq 0$ 的表达式称为 $x$ 的 锥组合. 若集合 $S$ 中任意点的锥组合都在 $S$ 中, 则称 $S$ 为凸锥.\n常见凸集 定义\n任取非零向量 $a\\in \\mathbb{R}^n$, 形如\n$$ \\left\\{ x \\mid a^Tx =b \\right\\} $$的集合称为 超平面, 形如\n$$ \\left\\{ x \\mid a^Tx \\le b \\right\\} $$的集合称为 半空间.\n定义\n满足线性等式和不等式组的点的集合称为 多面体, 即\n$$ \\left\\{x \\mid Ax \\le b, Cx = d\\right\\} $$其中 $A \\in \\mathbb{R}^{m \\times n}, C \\in \\mathbb{R}^{p \\times n}$.\n定义\n对中心 $x_c$ 和半径 $r$, 形如\n$$ B(x_c, r) = \\left\\{ x \\mid \\Vert x - x_c \\Vert \\le r \\right\\} = \\left\\{ x_c + ru \\mid \\Vert u \\Vert \\le 1 \\right\\} $$的集合称为 球.\n对中心 $x_c$ 和对称正定矩阵 $P$, 非奇异矩阵 $A$, 形如\n$$ \\left\\{ x \\mid (x-x_c)^TP(x-x_c) \\le 1 \\right\\} = \\left\\{ x_c + Au \\mid \\Vert u \\Vert \\le 1 \\right\\} $$的集合称为 椭球.\n定义\n形如\n$$ \\left\\{(x,t) \\mid \\Vert x \\Vert \\le t \\right\\} $$的集合称为 (范数)锥.\n保凸运算 定理\n仿射运算保凸, 即对 $f(x)=Ax+b$, 则凸集在 $f$ 下的像是凸集, 凸集在 $f$ 下的原像是凸集.\n考虑双曲锥\n$$ \\left\\{ x \\mid x^TPx \\le \\left( c^Tx \\right)^2, c^Tx \\ge 0, P \\in \\mathbb{S}_+^n \\right\\} $$$\\mathbb{S}_+^n$ 表示半正定矩阵. 双曲锥可以表示为二阶锥\n$$ \\left\\{ x \\mid \\Vert Ax \\Vert_2 \\le c^Tx, c^Tx \\ge 0, A^TA = P \\right\\} $$这个可以由二次范数锥得到.\n透视变换 $P: \\mathbb{R}^{n+1} \\mapsto \\mathbb{R}^n$:\n$$ P(x,t) = \\frac{x}{t}, \\quad \\text{dom} P = \\left\\{ (x,t) \\mid t \u003e 0 \\right\\} $$保凸.\n分式线性变换 $f: \\mathbb{R}^n \\mapsto \\mathbb{R}^m$:\n$$ f(x) = \\frac{Ax+b}{c^Tx+d}, \\quad \\text{dom} f = \\left\\{ x \\mid c^Tx+d \u003e 0 \\right\\} $$保凸.\n广义不等式和对偶锥 定义\n我们称一个凸锥 $K \\subseteq \\mathbb{R}^n$ 为 适当锥, 当其还满足\n$K$ 是闭集; $K$ 是实心的, 即 $\\text{int} K \\neq \\emptyset$; $K$ 是尖的, 即内部不包含直线: 若 $x \\in \\text{int} K, -x \\in \\text{int} K$. 则一定有 $x = 0$. 例如\n非负卦限 $K=\\mathbb{R}_+^n=\\left\\{ x \\in \\mathbb{R}^n \\mid x_i \\ge 0 \\right\\}$ 是适当锥. 半正定锥 $K=\\mathbb{S}_+^n$ 是适当锥. $[0,1]$ 上的有限非负多项式 $K=\\left\\{ x \\in \\mathbb{R}^n \\mid x_1 + x_2t + \\cdots + x_nt^{n-1} \\ge 0, t \\in [0,1] \\right\\}$ 是适当锥. 可以在 适当锥 上定义广义不等式.\n定义\n对于适当锥 $K$ , 定义偏序 广义不等式 为\n$$x \\preceq_K y \\Leftrightarrow y - x \\in K$$严格版本:\n$$x \\prec_K y \\Leftrightarrow y - x \\in \\text{int} K$$ 广义不等式是一个偏序关系, 具有自反性, 反对称性, 传递性, 可加性, 非负缩放性, 不再赘述.\n定义\n令锥 $K$ 为全空间 $\\Omega$ 的子集, 则 $K$ 的对偶锥为\n$$ K^\\ast = \\left\\{ y \\mid \\langle x, y \\rangle \\ge 0, \\forall x \\in K \\right\\} $$ 例如\n非负卦限是自对偶锥. 半正定锥是自对偶锥. 定理\n设 $K$ 是一锥, $K^\\ast$ 是其对偶锥, 则满足:\n$K^\\ast$ 是锥 (即使 $K$ 不是锥); $K^\\ast$ 是凸且闭的; 若 $\\text{int} \\neq \\emptyset$, 则 $K^\\ast$ 是尖的. 若 $K$ 是尖的, 则 $\\text{int} K^\\ast \\neq \\emptyset$. 若 $K$ 是适当锥, 则 $K^\\ast$ 是适当锥. $K^{\\ast\\ast}$ 是 $K$ 的凸包. 特别地, 若 $K$ 是凸且闭的, 则 $K^\\ast=K$. 适当锥的对偶锥仍是适当锥, 则适当锥 $K$ 的对偶锥 $K^\\ast$ 也可以诱导广义不等式.\n定义\n对于适当锥 $K$, 定义其对偶锥 $K^\\ast$ 上的 对偶广义不等式 为:\n$$x \\preceq_{K^\\ast} y \\Leftrightarrow y - x \\in K^\\ast$$其满足\n$x \\preceq_{K} y \\Leftrightarrow \\lambda^Tx \\le \\lambda^Ty, \\forall \\lambda \\succeq_{K^\\ast} K^\\ast$. $y \\succeq_{K^\\ast} 0 \\Leftrightarrow y^Tx \\ge 0, \\forall x \\succeq_K 0$. 分离超平面定理 定理分离超平面定理\n如果 $C$ 和 $D$ 是不相交的凸集, 则存在一个超平面 $H$ 将 $C$ 和 $D$ 分开, 即存在 $a \\neq 0, b$ 使得\n$$ \\begin{aligned} a^Tx \u0026\\le b, \\quad \\forall x \\in C \\\\ a^Tx \u0026\\ge b, \\quad \\forall x \\in D \\end{aligned} $$ 简要想法是找距离最近的一对点, 以这两点的中点为中心, 以两点的连线为法向量构造超平面.\n定理严格分离定理\n如果 $C$ 和 $D$ 是不相交的凸集, 且 $C$ 是闭集, $D$ 是紧集, 则存在一个超平面 $H$ 将 $C$ 和 $D$ 严格分开, 即存在 $a \\neq 0, b$ 使得\n$$ \\begin{aligned} a^Tx \u0026\\lt b, \\quad \\forall x \\in C \\\\ a^Tx \u0026\\gt b, \\quad \\forall x \\in D \\end{aligned} $$ 定义\n给定集合 $C$ 和边界点 $x_0$, 如果 $a\\ne 0$ 满足 $a^Tx \\le a^T x_0, \\forall x \\in C$, 则称\n$$ \\left\\{ x \\mid a^Tx = a^T x_0 \\right\\} $$为 $C$ 的 支撑超平面.\n由分离超平面的特殊情况 ($D$ 为单点集) 可以得到支撑超平面的存在性.\n定理支撑超平面定理\n若 $C$ 是凸集, 则 $C$ 的任意边界点处存在支撑超平面.\n","date":"2025-01-16T00:00:00Z","permalink":"https://LeoDreamer2004.github.io/p/opt-method/convex-set/","title":"最优化方法(2) —— 凸集"},{"content":" 本节课件链接\n概要 最优化问题的一般形式:\n$$ \\begin{aligned} \\min_{x} \\quad \u0026 f(x) \\\\ \\text{s.t.} \\quad \u0026 g_i(x) \\leq 0, \\quad i = 1, 2, \\ldots, m \\\\ \u0026 h_j(x) = 0, \\quad j = 1, 2, \\ldots, p \\end{aligned} $$稀疏优化 考虑线性方程组 $Ax = b$, 优化函数 $\\min_{x \\in R^n} {\\Vert x \\Vert}_0, {\\Vert x \\Vert}_1, {\\Vert x \\Vert}_2$, 分别指代 $x$ 的非零元个数, $l_1, l_2$ 范数. LASSO(least absolute shrinkage and selection operator) 问题:\n$$ \\min_{x \\in \\mathbb{R}^n} \\mu {\\Vert x \\Vert}_1 + \\frac{1}{2} {\\Vert Ax - b \\Vert}_2^2 $$低秩矩阵优化 考虑矩阵 $M$, 希望 $X$ 在描述 $M$ 有效特征元素的同时, 尽可能保证 $X$ 的低秩性质. 低秩矩阵问题:\n$$ \\min_{X \\in \\mathbb{R}^{m \\times n}} \\text{rank}(X) \\quad \\text{s.t.} \\quad X_{ij} = M_{ij}, \\quad (i, j) \\in \\Omega $$核范数 ${\\Vert X \\Vert}_*$ 为所有奇异值的和. 也有二次罚函数的形式:\n$$ \\min_{X \\in \\mathbb{R}^{m \\times n}} \\mu {\\Vert X \\Vert}_* + \\frac{1}{2} \\sum_{(i,j)\\in \\Omega} (X_{ij} - M_{ij})^2 $$对于低秩情形, $X=LR^T$, 其中 +$L \\in \\mathbb{R}^{m \\times r}, R \\in \\mathbb{R}^{n \\times r}$, $r \\ll m,n$ 为秩. 优化问题可写为:\n$$ \\min_{L,R} \\alpha {\\Vert L \\Vert}^2_F + \\beta {\\Vert R \\Vert}^2_F + \\frac{1}{2} \\sum_{(i,j)\\in \\Omega} ([LR^T]_{ij} - M_{ij})^2 $$引入正则化系数 $\\alpha, \\beta$ 来消除 $L,R$ 在常数缩放下的不确定性.\n深度学习 机器学习的问题通常形如\n$$ \\min_{x \\in W} \\frac{1}{N} \\sum_{i=1}^N \\ell(f(a_i, x), b_i) + \\lambda R(x) $$ 基本概念 定义\n设 $f: \\mathbb{R}^n \\mapsto \\mathbb{R}$, $x \\in \\mathbb{R}^n$ 的可行区域为 $S$. 若存在一个邻域 $N(x)$, 使得 $\\forall x \\in N(x) \\cap S$, 有 $f(x^\\ast) \\leq f(x)$, 则称 $x^\\ast$ 为 $f$ 的局部极小点. 若 $\\forall x \\in S$, 有 $f(x^\\ast) \\leq f(x)$, 则称 $x^\\ast$ 为 $f$ 的全局极小点.\n大多数的问题是不能显式求解的, 通常要使用迭代算法.\n定义\n称算法是 Q-线性收敛 的, 若对充分大的 $k$ 有\n$$ \\frac{{\\Vert x_{k+1} - x^\\ast \\Vert}}{{\\Vert x_k - x^\\ast \\Vert}} \\le a, \\quad a \\in (0, 1) $$称算法是 Q-超线性收敛 的, 若对充分大的 $k$ 有\n$$ \\lim_{k \\to \\infty} \\frac{{\\Vert x_{k+1} - x^\\ast \\Vert}}{{\\Vert x_k - x^\\ast \\Vert}} = 0 $$称算法是 Q-次线性收敛 的, 若对充分大的 $k$ 有\n$$ \\lim_{k \\to \\infty} \\frac{{\\Vert x_{k+1} - x^\\ast \\Vert}}{{\\Vert x_k - x^\\ast \\Vert}} = 1 $$称算法是 Q-二次收敛 的, 若对充分大的 $k$ 有\n$$ \\frac{{\\Vert x_{k+1} - x^\\ast \\Vert}}{{\\Vert x_k - x^\\ast \\Vert^2}} \\le a, \\quad a \u003e 0 $$ 定义\n设 $x_k$ 是迭代算法产生的序列且收敛到 $x^\\ast$, 如果存在 Q-线性收敛于 $0$ 的非负序列 $t_k$, 且\n$$ \\Vert x_k - x^\\ast \\Vert \\le t_k $$则称 $x_k$ 是 R-线性收敛 的.\n一般来说, 收敛准则可以是\n$$ \\frac{f(x_k) - f^\\ast}{\\max\\left\\{\\left|f^\\ast \\right|, 1\\right\\}} \\le \\varepsilon $$也可以是\n$$ \\nabla f(x_k) \\le \\varepsilon $$如果有约束要求, 还要同时考虑到约束违反度. 对于实际的计算机算法, 会设计适当的停机准则, 例如\n$$ \\frac{{\\Vert x_{k+1} - x_k \\Vert}}{\\max\\left\\{\\Vert x_k \\Vert, 1\\right\\}} \\le \\varepsilon $$","date":"2025-01-12T00:00:00Z","permalink":"https://LeoDreamer2004.github.io/p/opt-method/intro/","title":"最优化方法(1) —— 简介"},{"content":"本系列是关于北大文再文老师最优化方法课程的自学笔记。\n导航\n博客页面 课件 最优化方法(1) —— 简介 课件链接 最优化方法(2) —— 凸集 课件链接 最优化方法(3) —— 凸函数 课件链接 最优化方法(4) —— 优化问题 课件链接 ","date":"2025-01-09T00:00:00Z","permalink":"https://LeoDreamer2004.github.io/p/opt-method/","title":"最优化方法"}]